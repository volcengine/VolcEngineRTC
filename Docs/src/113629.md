---
is_dir: False    # True for dir; False for doc
status: 1    # 1 for online; 0 for offline
keywords: 实时音视频    # use ',' as separator
---

在 RTC 通信时，如果你希望自动识别语音并转换为文本，可以使用实时语音识别（**A**utomatic **S**peech **R**ecognition） 相关接口实现。

## 功能详情

在客户端 SDK 开启 ASR 能力后，你可以在 RTC 的回调中实时获取语音识别的文本结果。

## 功能变更日志

1. 自客户端 SDK 3.25 起，ASR 的功能可用。

### 功能边界

- 无论音频输入是通过 RTC 内部音频采集还是自定义音频采集，都可以使用 RTC 集成的 ASR 能力。
- 不同场景下语音识别的效果以及对输入语音和输出语言的支持均由 ASR 分配的 业务集群（Cluster） 决定。我们建议提前与 ASR 技术支持确认实时语音识别的业务场景。
- 在RTC 通话中，一次实时语音识别的连续时长不建议超过 1 小时。
- 如果你需要使用 ASR 识别某个客户端（非本地客户端）采集的音频，你需要在该客户端开启 ASR 功能。

## 集成步骤

### 前提条件

在 ASR 控制台创建应用并获取 ASR 服务的相关信息，包括但不限于：
- AppId
- Access Token
- Secret Key（如选择 `signature` 鉴权方式）
- Cluster ID

详见 [ASR 鉴权说明](https://www.volcengine.com/docs/6561/107789)

### 调用时序

1. 加入 RTC 房间，采集并发布音频。
2. 启动 ASR 服务。
3. 收到回调，包含 ASR 识别得到的信息。
4. 关闭 ASR 服务。
5. 退出 RTC 房间。

![alt](https://lf3-volc-editor.volccdn.com/obj/volcfe/sop-public/upload_483f58f3db1e19c1011af7a2f5a20321.jpg)

### 最佳实践

- ASR 按照时长收费，为了更有效利用 ASR 时长，建议仅在本地采集并发布 RTC 音频时，开启 ASR 服务。例如，调用 [stopAudioCapture](70080.md#RTCVideo-stopaudiocapture) 或 [unpublishStream](70080.md#RTCRoom-unpublishstream) 时，关闭 ASR 服务。
- 使用过程中，如果 ASR 服务断连，那么重连后 ASR 返回的信息将不会包含断连前识别得到的信息。如果你根据业务逻辑需要获得此前识别得到的信息，建议在收到 onError 回调了解到 ASR 断连时，缓存已收到的语音识别信息。
- RTC 提供的 ASR 能力支持各种采样率的音频识别，推荐的音频采样率为 8 KHz 或 16 KHz。

## API Reference

### Android

- [startASR](70080.md#RTCVideo-startasr)
- [stopASR](70080.md#RTCVideo-stopasr)

### iOS

- [startASR:handler:](70086.md#ByteRTCVideo-startasr-handler)
- [stopASR](70086.md#ByteRTCVideo-stopasr)
