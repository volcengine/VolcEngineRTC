---
is_dir: False    # True for dir; False for doc
status: 1    # 0 for offline; 1 for online; 2 for whitelist; 4 for online but hidden in TOC
keywords: 实时音视频    # use ',' as separator
---

集成 RTC SDK 后，你可以使用其中接口快速构建基础应用，实现基本实时音视频通话；你也能通过阅读代码，了解音视频通话的最佳实践。 
如果你想了解完整的项目实现，参看 [Demo 工程文件](1163793)。

## 前提条件

- Xcode 12.5+ 版本（本文涉及编译器的指引及示例图均参考 Xcode 14.0.1 ）
- 支持 macOS 10.10+ 的设备
- 获取 [AppID](69865)
- 已获取 RTC [SDK 文件](75707#下载-sdk)
	

## 集成SDK

### 步骤1:（可选）创建项目

如集成到已有项目，请直接查看步骤 2。

1. 打开 Xcode， 创建适用于 macOS 的新项目（App）。
	
	![](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_e11292f859f1ee4210fa492dde4179db.png)
	
2. 输入项目名称、团队名称，选择开发语言（选择 Objective-C 或者 Swift）。
	
	![](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_686c4cc3da2ad1b10c39f75b19b0fb05.png)
	
3. 选择项目存储位置，并创建。
	
4. 签名设置：进入 `TARGETS > Project Name  > Signing & Capabilities` ，勾选 `Automatically manage signing`，并在弹出菜单中选择 `Enable Automatic`。
	
	![](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_65e023eab38e38e6b3e043f73f37d383.png)
	

### 步骤2： 引入 RTC SDK

将以下文件拖入到工程中：
- `libbytevc0.dylib`
- `libeffect.dylib`
- `RTCFFmpeg.framework`
- `VolcEngineRTC.framework`

	![](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_5f81c1960550299a017c1a7757ca7f46.png)

### 步骤3：配置项目属性

1. 配置音视频权限
	1. 找到项目中的 `info.plist` 文件
	2. 点击 【 + 】 添加音频和视频设备权限：
		1. `Privacy - Microphone Usage Description` ，并填入使用麦克风的原因（ Value ）
		2. `Privacy - Camera Usage Description` ，并填入使用摄像头的原因（ Value )
			
	![](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_16538d56e48ba96a73295c5d7217ecbb.png)
	

2. SDK 配置<span id="dependency"></span>
	
	进入 `TARGETS > Project Name  > General`，选择 `Frameworks, Libraries, and Embedded Content`，将 `libAGFX.dylib`、`libbytenn.dylib`、`libbytevc0.dylib`、`libeffect.dylib`、`RTCFFmpeg.framework` 和 `VolcEngineRTC.framework` 设置为 `Embed & Sign`。
	![](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_3236197d5eefb5a6b8c069d5355093c1.png)
	

## 实现音视频通话

参考以下的时序图：

![alt](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_1718959ff89738d318579b0e8f9a53c1.png)

1.（可选）创建用户界面

根据场景需要，为你的项目创建音视频通话的用户界面。若已有用户界面，跳过此步骤。

如果你想实现基本的音视频通话，我们建议你在项目中添加如下元素：

- 房间ID
- 用户 ID
- 本地视频窗口
- 远端视频窗口
- 打开麦克风按钮
- 打开摄像头按钮
- 结束通话按钮
	
![](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_6e51654527d8565b573c0dc26b925997.png)

2. 引入头文件

在使用 SDK API 的文件中引入头文件。

```objectivec
//引入 VolcEngineRTC 头文件
#import <VolcEngineRTC/VolcEngineRTC.h>
```

3. 创建引擎实例 [createRTCVideo](macOS-api#ByteRTCVideo-creatertcvideo-delegate-parameters)

调用 `createRTCVideo:delegate:parameters:` 接口，创建一个引擎实例，以使用 RTC 提供的各种音视频能力。

4. 设置视频编码参数 [setMaxVideoEncoderConfig:](macOS-api#ByteRTCVideo-setmaxvideoencoderconfig)

创建引擎实例后，你可以设置视频编码参数修改推送的视频流属性。

5. 设置本地视图 [setLocalVideoCanvas](macOS-api#ByteRTCVideo-setlocalvideocanvas-withcanvas)

加入房间前，你需要设置本地视图以在通话中看到本地图像

6. 开始视频采集 [startVideoCapture](macOS-api#ByteRTCVideo-startvideocapture)

创建引擎实例后，你需要开启视频采集，以在通话中使用视频功能。

7. 开始音频采集 [startAudioCapture](macOS-api#startaudiocapture)

创建引擎实例后，你需要开启音频采集，以在通话中使用音频功能。

8. 创建房间实例 [createRTCRoom](macOS-api#creatertcroom)

创建一个房间实例，以使用房间相关的功能。

9.设置房间回调事件

调用类 `ByteRTCRoom` 中的 `delegate` 接口，设置房间回调事件

10. 加入房间 [joinRoom](macOS-api#ByteRTCRoom-joinroom-userinfo-roomconfig)

创建房间实例后，你就可以调用 `ByteRTCRoom` 类中的 `joinRoom` 方法创建/加入房间。

11. 处理加入房间结果回调 [onRoomStateChanged](macOS-callback#ByteRTCRoomDelegate-rtcroom-onroomstatechanged-withuid-state-extrainfo)

加入房间后，你需要在此回调中处理首次加入房间/重连加入房间的事件。

12. 处理远端用户加入房间的回调 [onUserJoined](macOS-callback#ByteRTCRoomDelegate-rtcroom-onuserjoined-elapsed)

加入房间后，你需要在此回调中处理远端用户加入房间的事件。

13. 处理远端视频首帧解码的回调 [onFirstRemoteVideoFrameDecoded](macOS-callback#ByteRTCVideoDelegate-rtcengine-onfirstremotevideoframedecoded-withframeinfo)

加入房间后，你需要在此回调中处理第一帧远端视频流解码成功后的事件。

14. 设置远端视图 [setRemoteVideoCanvas:withCanvas:](macOS-api#ByteRTCVideo-setremotevideocanvas-withcanvas)

在确认收到远端用户的第一帧视频解码回调后，你需要设置远端视图以在通话中查看远端图像。

15. 处理远端用户离开房间的回调 [onUserLeave](macOS-callback#ByteRTCRoomDelegate-rtcroom-onuserleave-reason)

加入房间后，你需要在此回调中处理远端用户离开房间的事件。

16. 离开房间 [leaveRoom](macOS-api#ByteRTCRoom-leaveroom)

在结束通话等场景下，你需要调用 `leaveRoom` 离开房间，结束通话过程，释放所有通话相关的资源。

17. 销毁引擎实例 [destroyRTCVideo](macOS-api#ByteRTCVideo-destroyrtcvideo)

在 RTC 引擎实例相关的业务场景全部结束后，你可调用 `destroyRTCVideo` 销毁由 `createRTCVideo` 所创建引擎实例，并释放所有相关资源。

至此，我们实现了基本的音视频通话。

## 常见问题

1. 项目编译运行时，如果在加入房间控制台时，看到以下的报错信息 `dnssd_clientstub ConnectToServer: connect() failed path:/var/run/mDNSResponder Socket:20 Err:-1 Errno:1 Operation not permitted`，应进行相应处理：

	- 如果不使用 `App Sandbox`，删除即可;
	- 如果使用 `App Sandbox`，需要勾选 `Incoming Connections`、`Outgoing Connections`、`Camera` 和 `Audio Input`.

		![](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_0e655fc6085f9ddcca34f0abf9eeef89.png)

2. 在集成 RTC SDK 时，需要将 SDK 包引入到 app 中。若 SDK 包文件未放在默认目录下，会出现 RTC SDK 找不到依赖库（如 libbytenn、libbytevc0 等）的问题，从而引发卡死等问题，参看[解决方法](https://www.volcengine.com/docs/6348/1152682#rtc-sdk-%E6%89%BE%E4%B8%8D%E5%88%B0%E4%BE%9D%E8%B5%96%E5%BA%93%E9%97%AE%E9%A2%98)。
